{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TL;DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALG = RandomForestClassifier(n_estimators='warn', \n",
    "                             criterion='gini', \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='auto', \n",
    "                             max_leaf_nodes=None, \n",
    "                             min_impurity_decrease=0.0, \n",
    "                             min_impurity_split=None, \n",
    "                             bootstrap=True, \n",
    "                             oob_score=False, \n",
    "                             n_jobs=None, \n",
    "                             random_state=None, \n",
    "                             verbose=0, \n",
    "                             warm_start=False, \n",
    "                             class_weight=None)\n",
    "ALG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Example with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Files\n",
    "import pandas as pd # Tables\n",
    "import matplotlib.pyplot as plt # Plots\n",
    "from sklearn.model_selection import train_test_split # ML\n",
    "\n",
    "# Load cleaned and preprocessed CSV file as a dataframe.\n",
    "fp = os.path.join('', 'tweets_sentiment.csv')    # File path\n",
    "df = pd.read_csv(fp, sep='\\t', encoding='utf-8') # Load as dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example problem</b>: Predict tweet sentiment basing on it's  nr of hashtags, retweet and like counts. \n",
    "\n",
    "<b>Example data</b>: consists of 3800 tweets obtained by twitter search API on phrases like psychology + AI (and simillar) saved and cleaned previously as a tweets_sentiment.csv file. Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags_number</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanguardsw rt chboursin ai achieve human like ...</td>\n",
       "      <td>human-like skills</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>windy interview really groundbreaking can t wr...</td>\n",
       "      <td>interview groundbreaking. head DeepState reali...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai s top researchers think artificial general ...</td>\n",
       "      <td>ai’s ai artificialintelligence agi human</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  vanguardsw rt chboursin ai achieve human like ...   \n",
       "1  windy interview really groundbreaking can t wr...   \n",
       "2  ai s top researchers think artificial general ...   \n",
       "\n",
       "                                            hashtags  hashtags_number  likes  \\\n",
       "0                                  human-like skills                2      0   \n",
       "1  interview groundbreaking. head DeepState reali...                6      0   \n",
       "2           ai’s ai artificialintelligence agi human                5      1   \n",
       "\n",
       "   retweets  sentiment sentiment_class  \n",
       "0         7     0.2200        Positive  \n",
       "1         3     0.2000        Positive  \n",
       "2         0    -0.0125        Negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>tweet</b>           - tweet text.\n",
    "- <b>hashtags</b>        - #hashtags in a tweet.\n",
    "- <b>hashtags_number</b> - number of hashtags.\n",
    "- <b>likes</b>           - number of tweet likes \n",
    "- <b>retweets</b>        - number of times tweet have been shared.\n",
    "- <b>sentiment</b>       - score in range: -1.0 to 1.0 .\n",
    "- <b>sentiment_class</b> - score simplified to: Positive ( > 0) and Negative ( < 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example code:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - train: 0.76\n",
      "Accuracy - test:  0.67\n",
      "First three predictions (of 950): ['Positive' 'Positive' 'Positive'] ...\n",
      "First three propabilities (of 950): [[0.32203907 0.67796093]\n",
      " [0.2        0.8       ]\n",
      " [0.19761905 0.80238095]] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "# Divide data into features(X) and labels(y).\n",
    "y =  df.loc[ :, 'sentiment_class'] # column of labels to predict\n",
    "X =  df.loc[ :, ['retweets', 'likes', 'hashtags_number']] # columns of features used to predict label\n",
    "\n",
    "# Split both features(X) and labels(y) into training and testing datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Load and define Random Forest.\n",
    "RF = RandomForestClassifier(n_estimators='warn', \n",
    "                            criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, \n",
    "                            max_features='auto', \n",
    "                            max_leaf_nodes=None, \n",
    "                            min_impurity_decrease=0.0, \n",
    "                            min_impurity_split=None, \n",
    "                            bootstrap=True, \n",
    "                            oob_score=False, \n",
    "                            n_jobs=None, \n",
    "                            random_state=None, \n",
    "                            verbose=0, \n",
    "                            warm_start=False, \n",
    "                            class_weight=None)\n",
    "# Fit data into model.\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# Results.\n",
    "accuracy_train = round(RF.score(X_train, y_train), 2)\n",
    "accuracy_test  = round(RF.score(X_test,  y_test), 2)\n",
    "predictions = RF.predict(X_test) # an array.\n",
    "probabilities = RF.predict_proba(X_test) # an array.\n",
    "\n",
    "# Display results.\n",
    "print('Accuracy - train: {}\\nAccuracy - test:  {}\\nFirst three predictions (of {}): {} ...\\nFirst three propabilities (of {}): {} ...'.format(accuracy_train, accuracy_test, len(predictions), predictions[:3], len(probabilities), probabilities[:3]))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Key info\n",
    "\n",
    "- [ADD MORE],\n",
    "- (To be updated.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Get file\n",
    "import pandas as pd # Read as pandas table; dataframe (df).\n",
    "from sklearn.model_selection import train_test_split # Train/Test set divide.\n",
    "from sklearn.ensemble import RandomForestClassifier # Algorithm\n",
    "import matplotlib.pyplot as plt # Plots\n",
    "\n",
    "# You fill three lines below.\n",
    "# ---------------------------\n",
    "file_name   = 'your file_name.csv' # csv file in same dir  as this notebook.\n",
    "predit_what = 'column_name' # The label to predict.\n",
    "based_on    = ['column_name', 'column_name'] # The features to use in this quest.\n",
    "\n",
    "# You may wany to change full file path / use existing dataframe. \n",
    "fp = os.path.join('', file_name) # fp = 'home/data/file_path.csv'\n",
    "df = pd.read_csv(fp, sep='\\t', encoding='utf-8') # df = my_df \n",
    "\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "# Divide data into features(X) and labels(y).\n",
    "X =  df.loc[ :, based_on]    # features\n",
    "y =  df.loc[ :, predit_what] # label\n",
    "\n",
    "# Split both features(X) and labels(y) into training and testing datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Load and define Random Forest.\n",
    "RF = RandomForestClassifier(n_estimators='warn', \n",
    "                            criterion='gini', \n",
    "                            max_depth=None, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, \n",
    "                            max_features='auto', \n",
    "                            max_leaf_nodes=None, \n",
    "                            min_impurity_decrease=0.0, \n",
    "                            min_impurity_split=None, \n",
    "                            bootstrap=True, \n",
    "                            oob_score=False, \n",
    "                            n_jobs=None, \n",
    "                            random_state=None, \n",
    "                            verbose=0, \n",
    "                            warm_start=False, \n",
    "                            class_weight=None)\n",
    "# Fit data into model.\n",
    "RF.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "# Results.\n",
    "accuracy_train = round(RF.score(X_train, y_train), 2)\n",
    "accuracy_test  = round(RF.score(X_test,  y_test), 2)\n",
    "predictions = RF.predict(X_test) # an array.\n",
    "probabilities = RF.predict_proba(X_test) # an array.\n",
    "\n",
    "# Display results.\n",
    "print('Accuracy - train: {}\\nAccuracy - test:  {}\\nFirst three predictions (of {}): {} ...\\nFirst three propabilities (of {}): {} ...'.format(accuracy_train, accuracy_test, len(predictions), predictions[:3], len(probabilities), probabilities[:3]))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # Algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fp = os.path.join('', 'your file_name.csv')\n",
    "df = pd.read_csv(fp, sep='\\t', encoding='utf-8')\n",
    "\n",
    "X =  df.loc[ :, ['feature_column_name', 'feature_column_name']]\n",
    "y =  df.loc[ :, 'label_column_name']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "RF = RandomForestClassifier(max_features=3, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "accuracy_train = round(RF.score(X_train, y_train), 2)\n",
    "accuracy_test  = round(RF.score(X_test,  y_test), 2)\n",
    "predictions = RF.predict(X_test)\n",
    "probabilities = RF.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy - train: {}\\nAccuracy - test:  {}\\nFirst three predictions (of {}): {} ...\\nFirst three propabilities (of {}): {} ...'.format(accuracy_train, accuracy_test, len(predictions), predictions[:3], len(probabilities), probabilities[:3]))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More\n",
    "\n",
    "To be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Luke, 13 II 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
