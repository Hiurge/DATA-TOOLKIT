{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Getting tweets from user timeline\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "def connect_to_twitter(twitter_auth_path):\n",
    "    with open(twitter_auth_path, 'r') as f:\n",
    "        twitter_auth = json.load(f)\n",
    "        APP_KEY = twitter_auth['APP_KEY'] # your app key\n",
    "        APP_SECRET = twitter_auth['APP_SECRET'] # your app secret\n",
    "        OAUTH_TOKEN = twitter_auth['OAUTH_TOKEN'] # your oauth token\n",
    "        OAUTH_TOKEN_SECRET = twitter_auth['OAUTH_TOKEN_SECRET'] # your oauth token secret\n",
    "    twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "    return twitter\n",
    "\n",
    "# Picking intresting data from Twitter API response file\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def get_tweet_data(tweet, tweet_data):        \n",
    "    tweet_data['text'] = tweet['text']\n",
    "    tweet_data['hashtags'] = get_hashtags_string(tweet)\n",
    "    tweet_data['link'] = get_expanded_url_of_link_in_tweet(tweet)\n",
    "    tweet_data['tweet_id'] = tweet['id']\n",
    "    tweet_data['created_at'] = tweet['created_at']\n",
    "    tweet_data['retweet_count'] = tweet['retweet_count']\n",
    "    tweet_data['favorite_count'] = tweet['favorite_count']\n",
    "    tweet_data['in_reply_to_status_id'] = tweet['in_reply_to_status_id']\n",
    "    tweet_data['in_reply_to_screen_name'] = tweet['in_reply_to_screen_name']    \n",
    "    return tweet_data\n",
    "\n",
    "def get_tweet_author_data(tweet, tweet_data):\n",
    "    tweet_data['author'] = tweet['user']['screen_name']\n",
    "    tweet_data['account_created_at'] = tweet['user']['created_at']\n",
    "    tweet_data['author_description'] = tweet['user']['description']\n",
    "    tweet_data['author_id'] = tweet['user']['id']\n",
    "    tweet_data['author_location'] = tweet['user']['location']\n",
    "    tweet_data['author_statuses_count'] = tweet['user']['statuses_count']\n",
    "    tweet_data['author_followers_count'] = tweet['user']['followers_count']\n",
    "    tweet_data['author_friends_count'] = tweet['user']['friends_count']\n",
    "    tweet_data['author_favourites_count'] = tweet['user']['favourites_count']\n",
    "    tweet_data['author_listed_count'] = tweet['user']['listed_count']\n",
    "    tweet_data['author_url'] = get_expanded_url_of_link_in_author_account(tweet)   \n",
    "    return tweet_data\n",
    "\n",
    "# Helpers for extracting Twitter API response file\n",
    "# ------------------------------------------------\n",
    "\n",
    "def get_hashtags_string(tweet):\n",
    "    hashtags_string = ''\n",
    "    for nr in range(len(tweet['entities']['hashtags'])):\n",
    "        hashtags_string += tweet['entities']['hashtags'][nr]['text'] + ' '\n",
    "    if not hashtags_string:\n",
    "        hashtags_string = 'NO_HASHTAGS'\n",
    "    return hashtags_string\n",
    "\n",
    "def get_expanded_url_of_link_in_tweet(tweet):\n",
    "    url = tweet['entities']['urls']\n",
    "    if url:\n",
    "        return url[0]['expanded_url']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_expanded_url_of_link_in_author_account(tweet):\n",
    "    url = tweet['user']['entities']['url']['urls']\n",
    "    if url:\n",
    "        return url[0]['expanded_url']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Save tweets dataset\n",
    "# -------------------\n",
    "\n",
    "def save_tweets_as_CSV(save_path, all_tweets_list, tweet_nr):\n",
    "    tweet_df = pd.DataFrame(all_tweets_list)\n",
    "    tweet_df.to_csv(save_path+'.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "    print('{} tweets saved to {}'.format(tweet_nr, save_path+'.csv'))\n",
    "\n",
    "def save_tweets_as_JSON(save_path, all_tweets, tweet_nr):\n",
    "    with open(save_path+'.json', 'w') as f:\n",
    "        json.dump(all_tweets, f)\n",
    "        print('{} tweets saved to {}'.format(tweet_nr, save_path+'.json'))\n",
    "\n",
    "# Main\n",
    "# ----\n",
    "\n",
    "def get_twitter_user_timeline(twitter, account_name):\n",
    "    search_pages = twitter.cursor(twitter.get_user_timeline, screen_name=account_name, return_pages=True, count=200)\n",
    "    return search_pages\n",
    "\n",
    "def get_all_tweets_from_user_timelne(search_pages, save_path):\n",
    "    try:\n",
    "        all_tweets, all_tweets_list = {}, []\n",
    "        tweet_nr, page_nr = 0, 0\n",
    "        for page in search_pages:\n",
    "            page_nr +=1\n",
    "            for tweet in page:\n",
    "                tweet_nr +=1\n",
    "                tweet_data = {}\n",
    "                tweet_data = get_tweet_data(tweet, tweet_data)\n",
    "                tweet_data = get_tweet_author_data(tweet, tweet_data)\n",
    "                all_tweets[str(tweet_nr)] = tweet_data\n",
    "                all_tweets_list.append(tweet_data)\n",
    "            print('Pages done: {}, tweets done: {}'.format(page_nr, tweet_nr))\n",
    "    except:\n",
    "        save_tweets_as_JSON(save_path, all_tweets, tweet_nr)\n",
    "        save_tweets_as_CSV(save_path, all_tweets_list, tweet_nr)\n",
    "\n",
    "def get_user_tweets(account_name, save_path, twitter_auth_path):\n",
    "    twitter = connect_to_twitter(twitter_auth_path)\n",
    "    search_pages = get_twitter_user_timeline(twitter, account_name)\n",
    "    get_all_tweets_from_user_timelne(search_pages, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages done: 1, tweets done: 200\n",
      "Pages done: 2, tweets done: 400\n",
      "Pages done: 3, tweets done: 600\n",
      "Pages done: 4, tweets done: 800\n",
      "Pages done: 5, tweets done: 999\n",
      "Pages done: 6, tweets done: 1199\n",
      "Pages done: 7, tweets done: 1399\n",
      "Pages done: 8, tweets done: 1598\n",
      "Pages done: 9, tweets done: 1798\n",
      "Pages done: 10, tweets done: 1998\n",
      "Pages done: 11, tweets done: 2198\n",
      "Pages done: 12, tweets done: 2398\n",
      "Pages done: 13, tweets done: 2598\n",
      "Pages done: 14, tweets done: 2798\n",
      "Pages done: 15, tweets done: 2997\n",
      "Pages done: 16, tweets done: 3197\n",
      "Pages done: 17, tweets done: 3205\n",
      "3205 tweets saved to MSFTResearch_timeline_tweets.json\n",
      "3205 tweets saved to MSFTResearch_timeline_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# Example with Microsoft Research Twitter page\n",
    "# --------------------------------------------\n",
    "\n",
    "account_name = 'MSFTResearch'  \n",
    "save_path = account_name + '_timeline_tweets'\n",
    "twitter_auth_path = 'twitter_auth.json'\n",
    "get_user_tweets(account_name, save_path, twitter_auth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets dataset shape: (3205, 2)\n",
      "Tweets dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@jennwvaughan and @hannawallach will lead a webinar on responsible #AI on January 24. Learn how to make detecting… https://t.co/PQWaLjBwrs</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As machine learning becomes more prevalent, it’s critical to guard against bias. Next week, Microsoft researchers J… https://t.co/adNgyL5Djq</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @erichorvitz: \"Boffins!\"@theregister @cervisiarius\\r\\n \"Computing boffins strip the fun out of satirical headlines\" https://t.co/G8rUsowsaT…</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Celebrate International Day of Women and Girls in Science at our I Chose STEM event in San Francisco! Speakers will… https://t.co/CdcDqqmP0z</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Push the state-of-the-art in software production as a researcher with @RiSE_MSR. Apply now if you're interested in… https://t.co/QvxL4nI0GU</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>University students are invited to identify and solve education pain-points through #AI for a chance to attend an a… https://t.co/5XTOzJ6CBF</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The entertainment industry has long offered us a vision of personal assistants that not only meet our stated needs… https://t.co/BIjNRQeHTb</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft researchers, engineers &amp;amp; collaborators are proving theorems about high performance, security critical cod… https://t.co/XphSCfR4nr</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @AndrewDGordon: Grad students, fancy an @MSFTResearchCam internship on PL applied to @msexcel spreadsheets - see https://t.co/LphKBlAu8N…</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"One of the joys of working at Microsoft Research is the ability to directly influence mainstream software technolo… https://t.co/Y1W4q8Hwuf</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "0       .@jennwvaughan and @hannawallach will lead a webinar on responsible #AI on January 24. Learn how to make detecting… https://t.co/PQWaLjBwrs   \n",
       "1      As machine learning becomes more prevalent, it’s critical to guard against bias. Next week, Microsoft researchers J… https://t.co/adNgyL5Djq   \n",
       "2   RT @erichorvitz: \"Boffins!\"@theregister @cervisiarius\\r\\n \"Computing boffins strip the fun out of satirical headlines\" https://t.co/G8rUsowsaT…   \n",
       "3      Celebrate International Day of Women and Girls in Science at our I Chose STEM event in San Francisco! Speakers will… https://t.co/CdcDqqmP0z   \n",
       "4       Push the state-of-the-art in software production as a researcher with @RiSE_MSR. Apply now if you're interested in… https://t.co/QvxL4nI0GU   \n",
       "5      University students are invited to identify and solve education pain-points through #AI for a chance to attend an a… https://t.co/5XTOzJ6CBF   \n",
       "6       The entertainment industry has long offered us a vision of personal assistants that not only meet our stated needs… https://t.co/BIjNRQeHTb   \n",
       "7  Microsoft researchers, engineers &amp; collaborators are proving theorems about high performance, security critical cod… https://t.co/XphSCfR4nr   \n",
       "8      RT @AndrewDGordon: Grad students, fancy an @MSFTResearchCam internship on PL applied to @msexcel spreadsheets - see https://t.co/LphKBlAu8N…   \n",
       "9      \"One of the joys of working at Microsoft Research is the ability to directly influence mainstream software technolo… https://t.co/Y1W4q8Hwuf   \n",
       "\n",
       "   retweet_count  \n",
       "0             12  \n",
       "1             67  \n",
       "2              9  \n",
       "3             16  \n",
       "4              9  \n",
       "5             15  \n",
       "6             10  \n",
       "7             25  \n",
       "8             17  \n",
       "9             56  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tweets from csv\n",
    "# --------------------\n",
    "\n",
    "tweets_df = pd.read_csv(save_path + \".csv\", sep='\\t', )\n",
    "tweets_df = tweets_df.loc[:,['text','retweet_count']]\n",
    "pd.options.display.max_colwidth = 300\n",
    "print(\"Tweets dataset shape: {}\".format(tweets_df.shape))\n",
    "print(\"Tweets dataset:\")\n",
    "tweets_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
