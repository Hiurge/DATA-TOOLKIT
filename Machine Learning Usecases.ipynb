{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cognitive compute human artificialintelligence...</td>\n",
       "      <td>Human ArtificialIntelligence fintech insurtech...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  cognitive compute human artificialintelligence...   \n",
       "\n",
       "                                            hashtags  retweet_count  \\\n",
       "0  Human ArtificialIntelligence fintech insurtech...           26.0   \n",
       "\n",
       "   favorite_count  sentiment  \n",
       "0            32.0        0.0  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('example_twitter_data_6k.csv', sep='\\t', encoding='utf-8')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3800, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>h_l</th>\n",
       "      <th>sent_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanguardsw rt chboursin ai achieve human like ...</td>\n",
       "      <td>human-like skills</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           hashtags  \\\n",
       "0  vanguardsw rt chboursin ai achieve human like ...  human-like skills   \n",
       "\n",
       "   retweet_count  favorite_count  sentiment  h_l  sent_class  \n",
       "0            7.0             0.0       0.22  1.0           1  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data - remake\n",
    "\n",
    "def set_sent_class(sent):\n",
    "    limit = 0.00\n",
    "    if sent > limit:\n",
    "        return 1 #'Positive'\n",
    "    elif sent < (limit*-1):\n",
    "        return -1 #'Negative'\n",
    "    else:\n",
    "        return 0 # 'Neutral'\n",
    "\n",
    "df = pd.read_csv('example_twitter_data_6k.csv', sep='\\t', encoding='utf-8')\n",
    "df = df[(df.sentiment != 0)].copy(deep=True).reset_index(drop=True)\n",
    "df['h_l'] = df.hashtags.str.count(' ') # Drop no-hashtags\n",
    "df['sent_class'] = df.sentiment.apply(set_sent_class)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/make-predictions-scikit-learn/\n",
    "https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9\n",
    "https://towardsdatascience.com/linear-regression-using-python-ce21aa90ade6\n",
    "https://www.thelearningmachine.ai/logistic?fbclid=IwAR1R22vWdtN-LrVl9ccatmHVBDZq8KTFllXKyGqosGT_M0L5ldoClcfNpbY\n",
    "https://github.com/5x12/ML-Cookbook/blob/master/Classification/logistic_regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "X = df[['horsepower']]\n",
    "y = df['price']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Feature Normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Dataset Description\n",
    "print('linear model coeff (w): {}'.format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test_scaled, y_test)))\n",
    "\n",
    "#### Example plot\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X, y, marker= 'o', s=50, alpha=0.8)\n",
    "plt.plot(X_train, linreg.coef_ * X_train + linreg.intercept_, 'r-')\n",
    "plt.title('Least-squares linear regression')\n",
    "plt.xlabel('Feature value (x)')\n",
    "plt.ylabel('Target value (y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model coeff (w): [157.09522969]\n",
      "linear model intercept (b): -3574.121\n",
      "R-squared score (training): 0.623\n",
      "R-squared score (test): 0.666\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "X = df[['horsepower']]\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "### intercept & coefficient, R-squared for training & test data set\n",
    "print('linear model coeff (w): {}'.format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "# Train/Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) # , train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Pick alghoritm \n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "\n",
    "# Fit model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "### intercept & coefficient, R-squared for training & test data set\n",
    "print('linear model coeff (w): {}'.format(lr.coef_))\n",
    "print('linear model intercept (b): {:.3f}'.format(lr.intercept_))\n",
    "print('R-squared score (training): {:.3f}'.format(lr.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np  # ?\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler  # ?\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state = 0)\n",
    "\n",
    "# Polynomial regression def\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "### intercept & coefficient, R-squared for training & test data set\n",
    "print('(poly deg 2) linear model coeff (w):\\n{}'.format(linreg.coef_))\n",
    "print('(poly deg 2) linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}\\n'.format(linreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Polynomial Regression model with a regularization penalty.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state = 0)\n",
    "linreg = Ridge().fit(X_train, y_train)\n",
    "\n",
    "### intercept & coefficient, R-squared for training & test data set\n",
    "print('(poly deg 2 + ridge) linear model coeff (w):\\n{}'.format(linreg.coef_))\n",
    "print('(poly deg 2 + ridge) linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=2.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "\n",
    "### Intercept & coefficient, # of non-zero features & weights, R-squared for training & \n",
    "### test data set\n",
    "print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:{}'.format(linlasso.coef_))\n",
    "print('\\nNon-zero features: {}'.format(np.sum(linlasso.coef_ != 0)))\n",
    "print('\\nR-squared score (training): {:.3f}'.format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "for e in sorted (list(zip(list(X), linlasso.coef_)), key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))\n",
    "        \n",
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "# Regularization parameter alpha on R-squared\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}\\n'.format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "# Logistic regression regularization: C parameter\n",
    "for this_C in [0.1, 1, 100]:\n",
    "    clf = LogisticRegression(C=this_C).fit(X_train, y_train)\n",
    "    print('Logistic Regression with C = {}'.format(this_C))\n",
    "    print('Accuracy of Logistic regression classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "    print('Accuracy of Logistic regression classifier on test set: {:.2f}\\n'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count', 'retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train, y_train)\n",
    "print('Breast cancer dataset')\n",
    "print('Accuracy of GaussianNB classifier on training set: {:.2f}'\n",
    "     .format(nbclf.score(X_train, y_train)))\n",
    "print('Accuracy of GaussianNB classifier on test set: {:.2f}'\n",
    "     .format(nbclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Data Input Example \n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower']]\n",
    "y = df['price']\n",
    "\n",
    "X_2 = df[['horsepower', 'normalized-losses']]\n",
    "y_2 = df['price']\n",
    "\n",
    "from sklearn.svm import SVC\n",
    " \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "#C parameter\n",
    "this_C = 1.0\n",
    "\n",
    "# Linear SVM regularization: C parameter\n",
    "clf = SVC(kernel = 'linear', C=this_C).fit(X_train, y_train)\n",
    "print('Linear SVC, C = {:.3f}'.format(this_C))\n",
    "print('Accuracy of Linear SVC classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Linear SVC classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "# LinearSVC with M classes generates M one vs rest classifiers\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, random_state = 0)\n",
    "\n",
    "clf = LinearSVC(C=5, random_state = 67).fit(X_train, y_train)\n",
    "print('Coefficients:\\n', clf.coef_)\n",
    "print('Intercepts:\\n', clf.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernelized Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "# The default SVC kernel is radial basis function (RBF)\n",
    "clf = SVC().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of RBF-kernel SVC on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RBF-kernel SVC on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "### THIS MIGHT TAKE A WHILE\n",
    "# # Compare decision boundries with polynomial kernel, degree = 3\n",
    "# clf = SVC(kernel = 'poly', degree = 3).fit(X_train, y_train)\n",
    "\n",
    "# print('Accuracy of poly-kernel SVC on training set: {:.2f}'\n",
    "#      .format(clf.score(X_train, y_train)))\n",
    "# print('Accuracy of poly-kernel SVC on test set: {:.2f}'\n",
    "#      .format(clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Support Vector Machine with RBF kernel: gamma paramete\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "for this_gamma in [0.00001, 100]:\n",
    "    clf = SVC(kernel = 'rbf', gamma=this_gamma).fit(X_train, y_train)\n",
    "    print('SVM (RBF) with gamma = {}'.format(this_gamma))\n",
    "    print('Accuracy of SVM (RBF) classifier on training set: {:.2f}'\n",
    "         .format(clf.score(X_train, y_train)))\n",
    "    print('Accuracy of SVM (RBF) classifier on test set: {:.2f}\\n'\n",
    "         .format(clf.score(X_test, y_test)))\n",
    "    \n",
    "## Support Vector Machine with RBF kernel: using both C and gamma parameter\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "for this_gamma in [0.01, 1, 5]:\n",
    "    \n",
    "    for this_C in [0.1, 1, 15, 250]:\n",
    "        title = 'gamma = {:.2f}, C = {:.2f}'.format(this_gamma, this_C)\n",
    "        clf = SVC(kernel = 'rbf', gamma = this_gamma, C = this_C).fit(X_train, y_train)\n",
    "        print('SVM (RBF) with gamma = {} and C = {}'.format(this_gamma, this_C))\n",
    "        print('Accuracy of SVM (RBF) classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "        print('Accuracy of SVM (RBF) classifier on test set: {:.2f}\\n'.format(clf.score(X_test, y_test)))\n",
    "        \n",
    "#  SVMs with normalized data (feature preprocessing using minmax\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(C=10).fit(X_train_scaled, y_train)\n",
    "print('Cars dataset (normalized with MinMax scaling)')\n",
    "print('RBF-kernel SVC (with MinMax scaling) training set accuracy: {:.2f}'.format(clf.score(X_train_scaled, y_train)))\n",
    "print('RBF-kernel SVC (with MinMax scaling) test set accuracy: {:.2f}'.format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Data Input\n",
    "# df = \n",
    "\n",
    "### Defining Variables  \n",
    "# X = \n",
    "# y = \n",
    "\n",
    "### Data Input Example \n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower', 'normalized-losses']]\n",
    "y = df['price']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "clf = RandomForestClassifier(max_features = 2, random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower', 'normalized-losses']]\n",
    "y = df['price']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 3)\n",
    "clf = DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 8, random_state = 0).fit(X_train, y_train).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Data Input\n",
    "# df = \n",
    "\n",
    "### Defining Variables  \n",
    "# X = \n",
    "# y = \n",
    "\n",
    "### Data Input Example \n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower', 'normalized-losses']]\n",
    "y = df['price']\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "#### COMPARE YOUR MODELS ####\n",
    "\n",
    "# Model with the learning rate = 0.1 and max_dept = 3 (default settings)\n",
    "clf = GradientBoostingClassifier(random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Car dataset (learning_rate=0.1, max_depth=3)')\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}\\n'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "# Model with the learning rate = 0.01 and max_dept = 2\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 2, random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Car dataset (learning_rate=0.01, max_depth=2)')\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state = 0)\n",
    "# feature normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ridge regression def\n",
    "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "### intercept & coefficient, # of non-zero features & weights, R-squared for training & test data set\n",
    "print('Ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "print('Ridge regression linear model coeff: {}\\n'.format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'.format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'.format(np.sum(linridge.coef_ != 0)))\n",
    "\n",
    "# Regularization parameter alpha on R-squared\n",
    "\n",
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Get right data from data frame\n",
    "X = df.loc[:,['retweet_count']] # 'retweet_count', 'sentiment'\n",
    "y = df.sentiment # retweet_count\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# normalized\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model \n",
    "clf = MLPRegressor(hidden_layer_sizes = [100, 100], alpha = 5.0, random_state = 0, solver='lbfgs').fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy of NN regressor on training set: {:.2f}'.format(clf.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of NN regressor on test set: {:.2f}'.format(clf.score(X_test_scaled, y_test)))\n",
    "\n",
    "\n",
    "##### Accuracy with different activation functions and regularization parameter alpha\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# normalized\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Accuracy with different activation functions and regularization parameter alpha\n",
    "for thisactivation in ['tanh', 'relu']:\n",
    "    for thisalpha in [0.0001, 1.0, 100]:\n",
    "        mlpreg = MLPRegressor(hidden_layer_sizes = [100,100],\n",
    "                             activation = thisactivation,\n",
    "                             alpha = thisalpha,\n",
    "                             solver = 'lbfgs').fit(X_train, y_train)\n",
    "        print('Accuracy of NN regressor with activation funtion = {} and alpha = {} on training set: {:.2f}'.format(thisactivation, thisalpha, clf.score(X_train_scaled, y_train)))\n",
    "        print('Accuracy of NN regressor on test set: {:.2f}\\n'.format(clf.score(X_test_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - ClassificationÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Data Input\n",
    "# df = \n",
    "\n",
    "### Defining Variables  \n",
    "# X = \n",
    "# y = \n",
    "\n",
    "### Data Input Example \n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower', 'normalized-losses']]\n",
    "y = df['price']\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = 2, solver='lbfgs', random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of NN Classifier on training set: {:.2f}'.format(nnclf.score(X_train, y_train)))\n",
    "print('Accuracy of NN Classifier on test set: {:.2f}'.format(nnclf.score(X_test, y_test)))\n",
    "\n",
    "# Accuracy with different hidden layers\n",
    "\n",
    "for units in [1, 10, 100]:\n",
    "    nnclf = MLPClassifier(hidden_layer_sizes = [units], solver='lbfgs',\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    print('Accuracy of NN Classifier with hidden layers = {} on training set: {:.2f}'.format(units, nnclf.score(X_train, y_train)))\n",
    "    print('Accuracy of NN Classifier with hidden layers = {} on test set: {:.2f}\\n'.format(units, nnclf.score(X_test, y_test)))\n",
    "    \n",
    "\n",
    "# Accuracy with a regularization parameter: alpha\n",
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    nnclf = MLPClassifier(solver='lbfgs', activation = 'tanh',\n",
    "                         alpha = this_alpha,\n",
    "                         hidden_layer_sizes = [100, 100],\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    print('Accuracy of NN Classifier with alpha = {} on training set: {:.2f}'.format(units, nnclf.score(X_train, y_train)))\n",
    "    print('Accuracy of NN Classifier with alpha = {} on test set: {:.2f}\\n'.format(units, nnclf.score(X_test, y_test)))\n",
    "    \n",
    "    \n",
    "# Choices of activation function - tanh, logistic and relu\n",
    "\n",
    "# plot tanh, logistic and relu #Activation functions representation\n",
    "\n",
    "xrange = np.linspace(-2, 2, 200)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "plt.plot(xrange, np.maximum(xrange, 0), label = 'relu')\n",
    "plt.plot(xrange, np.tanh(xrange), label = 'tanh')\n",
    "plt.plot(xrange, 1 / (1 + np.exp(-xrange)), label = 'logistic')\n",
    "plt.legend()\n",
    "plt.title('Neural network activation functions')\n",
    "plt.xlabel('Input value (x)')\n",
    "plt.ylabel('Activation function output')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# The effect of different choices of activation function\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for this_activation in ['logistic', 'tanh', 'relu']:\n",
    "    nnclf = MLPClassifier(solver='lbfgs', activation = this_activation,\n",
    "                         alpha = 0.1, hidden_layer_sizes = [10, 10],\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    print('Accuracy of NN Classifier with {} activation function on training set: {:.2f}'.format(this_activation, nnclf.score(X_train, y_train)))\n",
    "    print('Accuracy of NN Classifier with {} activation function on test set: {:.2f}\\n'.format(this_activation, nnclf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "#  Accuracy with different activation functions and regularization parameter alpha\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "# Accuracy with different activation functions and regularization parameter alpha\n",
    "for thisactivation in ['tanh', 'relu']:\n",
    "    for thisalpha in [0.0001, 1.0, 100]:\n",
    "        nnclf = MLPClassifier(hidden_layer_sizes = [100,100],\n",
    "                             activation = thisactivation,\n",
    "                             alpha = thisalpha,\n",
    "                             solver = 'lbfgs').fit(X_train, y_train)\n",
    "        print('Accuracy of NN Classifier with activation funtion = {} and alpha = {} on training set: {:.2f}'.format(thisactivation, thisalpha, nnclf.score(X_train, y_train)))\n",
    "        print('Accuracy of NN Classifier with activation funtion = {} and alpha = {} on test set: {:.2f}\\n'.format(thisactivation, thisalpha, nnclf.score(X_test, y_test)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_training_data, y_training_data)\n",
    "prediction = model.predict(your_x_data)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# Cannot use Rank 1 matrix in scikit learn\n",
    "X = X.reshape((m, 1))\n",
    "# Creating Model\n",
    "reg = LinearRegression()\n",
    "# Fitting training data\n",
    "reg = reg.fit(X, Y)\n",
    "# Y Prediction\n",
    "Y_pred = reg.predict(X)\n",
    " \n",
    "# Calculating R2 Score\n",
    "r2_score = reg.score(X, Y)\n",
    " \n",
    "print(r2_score)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    ">>> lin_reg = LinearRegression()\n",
    ">>> lin_reg.fit(X, y)\n",
    ">>> lin_reg.intercept_, lin_reg.coef_\n",
    "(array([ 4.21509616]), array([[ 2.77011339]]))\n",
    ">>> lin_reg.predict(X_new)\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    " \n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
